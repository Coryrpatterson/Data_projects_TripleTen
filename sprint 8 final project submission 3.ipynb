{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hello Cory!\n",
    "\n",
    "I'm happy to review your project today.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  Thank you so much for your feedbacks. I've split the cells into multiple so it's easier. Hopefully i got it right this time. Thank you!\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a great job overall, but there are some small problems that need to be fixed before the project will be accepted. Let me know if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank has asked me to look at, and make predictions based on them losing customers at a steady pace. My goal with will be 1. See how many customers are still remaining at the bank, 2. make a prediction based on all the data how likely the remain customers are to leave. Finally, we will make some possible sugguestions to possibly help keep the customers loyal to Beta Bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "display(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers: 10000\n",
      "Number of customers still with the bank: 7963\n"
     ]
    }
   ],
   "source": [
    "total_customers = df.shape[0]\n",
    "remaining_customers = df[df['Exited'] == 0].shape[0]\n",
    "\n",
    "print(f\"Total number of customers: {total_customers}\")\n",
    "print(f\"Number of customers still with the bank: {remaining_customers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right! First step is down! We started off with 10,000 members and are now down to 7,963. Let's focus of the remaining members to see how likely they are to leave soon and then explore what we can do to keep them with us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843\n",
      "F1 Score: 0.470\n",
      "AUC-ROC Score: 0.842\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1547   26]\n",
      " [ 288  139]]\n"
     ]
    }
   ],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "X = df.drop(columns=['Exited']) \n",
    "y = df['Exited'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=12345)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")  \n",
    "print(f\"AUC-ROC Score: {roc_auc:.3f}\") \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct. But:\n",
    "    \n",
    "1. The main metric is F1 score but not accuracy. The additional metric is auc roc. You can calculate accuracy, if you want, but you should calculate f1 score and roc auc as well.\n",
    "2. Why didn't you use categorical features? You should encode them and use during model training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct. Good job!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction is looking great for us! According to the confusion matrix 1,573 customers stayed 68 of which were predicted to leave! The unfortunate side is that 427 customers are predicted to leave and 288 of those were predicted to stay! With an accuracy of 84.3%% I feel like its safe to say we can take that to the bank! Lets see if we can improve our F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['RowNumber', 'CustomerId',\n",
      "                                                   'CreditScore', 'Age',\n",
      "                                                   'Tenure', 'Balance',\n",
      "                                                   'NumOfProducts', 'HasCrCard',\n",
      "                                                   'IsActiveMember',\n",
      "                                                   'EstimatedSalary',\n",
      "                                                   'Surname_Abbie',\n",
      "                                                   'Surname_Abbott',\n",
      "                                                   'Surname_Abdullah',\n",
      "                                                   'Surname_Abdulov',\n",
      "                                                   'Surname_Abel',\n",
      "                                                   'Surname_Abernathy',\n",
      "                                                   'Surname_Abramov',\n",
      "                                                   'Surname_Ab...\n",
      "                                                   'Surname_Abramovich',\n",
      "                                                   'Surname_Abramowitz',\n",
      "                                                   'Surname_Abrego',\n",
      "                                                   'Surname_Abron',\n",
      "                                                   'Surname_Achebe',\n",
      "                                                   'Surname_Adams',\n",
      "                                                   'Surname_Adamson',\n",
      "                                                   'Surname_Afamefula',\n",
      "                                                   'Surname_Afamefuna',\n",
      "                                                   'Surname_Afanasyev',\n",
      "                                                   'Surname_Afanasyeva',\n",
      "                                                   'Surname_Agafonova', ...]),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(drop='first',\n",
      "                                                                handle_unknown='ignore'),\n",
      "                                                  [])])),\n",
      "                ('classifier', LogisticRegression(C=100, solver='liblinear'))])\n",
      "Accuracy: 0.690\n",
      "F1 Score: 0.349\n",
      "AUC-ROC Score: 0.576\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1214  359]\n",
      " [ 261  166]]\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = df.select_dtypes(exclude=['object']).drop(columns=['Exited']).columns.tolist()\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "df_majority = df_train[df_train['Exited'] == 0]\n",
    "df_minority = df_train[df_train['Exited'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,  \n",
    "                                 n_samples=len(df_majority),  \n",
    "                                 random_state=12345)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "X_train = df_upsampled.drop(columns=['Exited'])\n",
    "y_train = df_upsampled['Exited']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),  \n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features) \n",
    "])\n",
    "\n",
    "param_grid = {'classifier__C': [0.01, 0.1, 1, 10, 100], 'classifier__penalty': ['l1', 'l2']}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")  \n",
    "print(f\"AUC-ROC Score: {roc_auc:.3f}\")  \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct. Good job! But:\n",
    "\n",
    "1. You have already created variables X, y and splitted them above. You should not do the same thing for the second time here. So, please, clean your code\n",
    "2. Why didn't you use categorical features? You should encode them and use during model training.\n",
    "3. The main metric is F1 score but not accuracy. The additional metric is auc roc. You can calculate accuracy, if you want, but you should calculate f1 score and roc auc as well.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "If you're going to use any linear models, all quantitative features should be scaled. Not all features but only quantitative ones. Binary features which you got by one hot encoding have a perfect scale by default and additional scaling only ruins it. So, please, fix it.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Not fixed. You keep scaling all the features including binary ones.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like linear regression is not the way to go! Let's look at a few other possibilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, random_state=12345)\n",
      "Accuracy: 0.803\n",
      "F1 Score: 0.504\n",
      "AUC-ROC Score: 0.681\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1406  167]\n",
      " [ 227  200]]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced', random_state=12345)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1', verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")  \n",
    "print(f\"AUC-ROC Score: {roc_auc:.3f}\")  \n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(class_weight='balanced', max_depth=30, n_estimators=300,\n",
      "                       random_state=12345)\n",
      "Accuracy: 0.811\n",
      "F1 Score: 0.602\n",
      "AUC-ROC Score: 0.839\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1336  237]\n",
      " [ 141  286]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced', random_state=12345)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1', verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC Score: {roc_auc:.3f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct. Good job! But:\n",
    "\n",
    "1. You have already filled the NaNs, created variables X, y and splitted them above. You should not do the same thing for the second time here. So, please, clean your code\n",
    "2. The main metric is F1 score. The additional metric is auc roc. You should calculate both f1 score and roc auc.\n",
    "3. We need to scale the data only if we use linear models. For tree based models it is useless operation because scaling does not affect on tree based models. But if you use linear models, you need to scale only quantitative features because one hot encoded features have a perfect scale by default and additional scaling only ruins it.\n",
    "4. Please, try at least one more model while working with imbalance\n",
    "5. Please, try at least one more way to deal with imbalance. For instance, you can train a model with parameters class_weights='balanced'\n",
    "6. Please, tune hyperparameters at least for one model while working with imbalance. The easiest way is to GridSearcCV with a model with class_weights='balanced'.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "1. If you're going to use any linear models, all quantitative features should be scaled. Not all features but only quantitative ones. Binary features which you got by one hot encoding have a perfect scale by default and additional scaling only ruins it. So, please, fix it.\n",
    "2. Please, try at least one more model while working with imbalance. Right now you tried only one model (RandomForestClassifier) but you should try at least two models.\n",
    "3. Please, try at least one more way to deal with imbalance. For instance, you can apply upsampling or downsampling function for the train data. You have such examples in the lesson. You don't even need to tune hyperparameters in such case. Just try at least one model with upsampled or downsampled train data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Just for some clarification, I thought i had used 2 different models, liner regression and random forest classifier. Like i have talked with a tutor this section has logically made sense however the practical use has made zero sense. Am i wrong about the liner regression vs random forest classifier? Sorry for not getting this project at all and thanks for your paitence with me. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "You tried LogisticRegression before you started to work with imbalance. But in the section where you work with imbalance you need to try at least two models but now you tried only one RandomForestClassifier model.\n",
    "    \n",
    "So, all 3 problems from my previous comment are not fixed yet.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Prediction models are telling us that it looks like the worst is behind us! With more customers staying then leaving this should be music to our ears. As a side note of possibly keeping more customers with us here at Beta Bank, We could look into things such as higher interest rates on savings accounts, Loyalty gifts for those with higher tenure, or maybe even a cash back credit card. All that being said lets figure out more ways to keep those customers that are predicted to leave!"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2758,
    "start_time": "2025-03-13T02:58:50.367Z"
   },
   {
    "duration": 355,
    "start_time": "2025-03-13T03:00:07.182Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-13T03:00:13.256Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-13T03:00:25.059Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T03:07:54.263Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-13T03:10:29.029Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-13T03:10:43.671Z"
   },
   {
    "duration": 19,
    "start_time": "2025-03-13T03:11:00.282Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-13T03:11:16.474Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T03:13:01.082Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T03:15:10.391Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-13T03:15:25.281Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T03:15:33.222Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T03:15:51.250Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-13T03:15:59.606Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-13T03:16:18.150Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-13T03:21:51.288Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T03:29:19.606Z"
   },
   {
    "duration": 422,
    "start_time": "2025-03-13T03:41:31.474Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T03:41:50.724Z"
   },
   {
    "duration": 423,
    "start_time": "2025-03-13T03:42:17.722Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-13T03:42:28.701Z"
   },
   {
    "duration": 1528,
    "start_time": "2025-03-13T03:48:30.364Z"
   },
   {
    "duration": 1289,
    "start_time": "2025-03-13T03:54:14.887Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T03:54:16.178Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T03:54:16.180Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T03:54:16.181Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T03:54:16.182Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T04:03:14.710Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-13T04:03:16.944Z"
   },
   {
    "duration": 1141,
    "start_time": "2025-03-13T04:03:29.213Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-13T04:03:30.356Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T04:03:30.393Z"
   },
   {
    "duration": 553,
    "start_time": "2025-03-13T04:03:30.400Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:03:30.956Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-13T04:03:38.421Z"
   },
   {
    "duration": 1077,
    "start_time": "2025-03-13T04:05:24.398Z"
   },
   {
    "duration": 34,
    "start_time": "2025-03-13T04:05:25.478Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-13T04:05:25.514Z"
   },
   {
    "duration": 533,
    "start_time": "2025-03-13T04:05:25.532Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:05:26.067Z"
   },
   {
    "duration": 1015,
    "start_time": "2025-03-13T04:08:04.743Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T04:08:05.760Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T04:08:05.794Z"
   },
   {
    "duration": 276,
    "start_time": "2025-03-13T04:08:05.801Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:08:06.079Z"
   },
   {
    "duration": 1016,
    "start_time": "2025-03-13T04:10:38.603Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T04:10:39.623Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T04:10:39.656Z"
   },
   {
    "duration": 1288,
    "start_time": "2025-03-13T04:10:39.662Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-13T04:10:40.953Z"
   },
   {
    "duration": 1201,
    "start_time": "2025-03-13T04:11:23.209Z"
   },
   {
    "duration": 227,
    "start_time": "2025-03-13T04:15:54.859Z"
   },
   {
    "duration": 673,
    "start_time": "2025-03-13T04:16:09.690Z"
   },
   {
    "duration": 667,
    "start_time": "2025-03-13T04:16:18.141Z"
   },
   {
    "duration": 633,
    "start_time": "2025-03-13T04:25:02.943Z"
   },
   {
    "duration": 1187,
    "start_time": "2025-03-13T04:29:43.654Z"
   },
   {
    "duration": 1199,
    "start_time": "2025-03-13T04:31:35.330Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-13T04:35:05.043Z"
   },
   {
    "duration": 658,
    "start_time": "2025-03-13T04:35:18.091Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-13T04:42:38.302Z"
   },
   {
    "duration": 998,
    "start_time": "2025-03-13T04:44:26.967Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-13T04:44:27.968Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T04:44:28.000Z"
   },
   {
    "duration": 428,
    "start_time": "2025-03-13T04:44:28.024Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:44:28.454Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:44:28.455Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T04:44:28.457Z"
   },
   {
    "duration": 90,
    "start_time": "2025-03-13T04:46:56.518Z"
   },
   {
    "duration": 675,
    "start_time": "2025-03-13T04:47:14.470Z"
   },
   {
    "duration": 662,
    "start_time": "2025-03-13T04:47:59.064Z"
   },
   {
    "duration": 886,
    "start_time": "2025-03-13T04:48:28.804Z"
   },
   {
    "duration": 904,
    "start_time": "2025-03-13T04:49:49.710Z"
   },
   {
    "duration": 1211,
    "start_time": "2025-03-13T04:50:08.474Z"
   },
   {
    "duration": 648,
    "start_time": "2025-03-13T04:50:53.660Z"
   },
   {
    "duration": 997,
    "start_time": "2025-03-13T04:59:32.424Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T04:59:33.423Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-13T04:59:33.456Z"
   },
   {
    "duration": 691,
    "start_time": "2025-03-13T04:59:33.463Z"
   },
   {
    "duration": 905,
    "start_time": "2025-03-13T04:59:34.157Z"
   },
   {
    "duration": 1213,
    "start_time": "2025-03-13T04:59:35.064Z"
   },
   {
    "duration": 9,
    "start_time": "2025-03-13T08:47:34.776Z"
   },
   {
    "duration": 163,
    "start_time": "2025-03-13T18:08:36.078Z"
   },
   {
    "duration": 2791,
    "start_time": "2025-03-13T18:08:47.135Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-13T18:08:49.928Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:08:49.967Z"
   },
   {
    "duration": 193,
    "start_time": "2025-03-13T18:08:49.973Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:08:50.168Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:08:50.169Z"
   },
   {
    "duration": 596,
    "start_time": "2025-03-13T18:10:11.537Z"
   },
   {
    "duration": 54,
    "start_time": "2025-03-13T18:12:32.214Z"
   },
   {
    "duration": 1130,
    "start_time": "2025-03-13T18:12:48.717Z"
   },
   {
    "duration": 43,
    "start_time": "2025-03-13T18:12:49.850Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T18:12:49.895Z"
   },
   {
    "duration": 237,
    "start_time": "2025-03-13T18:12:49.903Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:12:50.142Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:12:50.143Z"
   },
   {
    "duration": 521,
    "start_time": "2025-03-13T18:13:02.621Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:13:23.060Z"
   },
   {
    "duration": 51,
    "start_time": "2025-03-13T18:14:44.707Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-13T18:16:34.162Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:16:54.814Z"
   },
   {
    "duration": 50,
    "start_time": "2025-03-13T18:17:23.016Z"
   },
   {
    "duration": 70,
    "start_time": "2025-03-13T18:18:13.955Z"
   },
   {
    "duration": 96,
    "start_time": "2025-03-13T18:18:58.413Z"
   },
   {
    "duration": 204,
    "start_time": "2025-03-13T18:19:32.660Z"
   },
   {
    "duration": 146,
    "start_time": "2025-03-13T18:20:10.152Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-13T18:20:48.648Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:20:52.179Z"
   },
   {
    "duration": 94,
    "start_time": "2025-03-13T18:21:25.248Z"
   },
   {
    "duration": 97,
    "start_time": "2025-03-13T18:21:45.302Z"
   },
   {
    "duration": 1036,
    "start_time": "2025-03-13T18:22:03.765Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-13T18:22:04.803Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-13T18:22:04.851Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:22:04.864Z"
   },
   {
    "duration": 695,
    "start_time": "2025-03-13T18:22:04.869Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:22:05.566Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:22:05.568Z"
   },
   {
    "duration": 1122,
    "start_time": "2025-03-13T18:22:31.880Z"
   },
   {
    "duration": 38,
    "start_time": "2025-03-13T18:22:33.004Z"
   },
   {
    "duration": 19,
    "start_time": "2025-03-13T18:22:33.044Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:22:33.065Z"
   },
   {
    "duration": 327,
    "start_time": "2025-03-13T18:22:33.070Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:22:33.399Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:22:33.400Z"
   },
   {
    "duration": 610,
    "start_time": "2025-03-13T18:22:50.653Z"
   },
   {
    "duration": 1053,
    "start_time": "2025-03-13T18:23:00.785Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-13T18:23:01.840Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:23:01.886Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:23:01.892Z"
   },
   {
    "duration": 227,
    "start_time": "2025-03-13T18:23:01.897Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:23:02.125Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:23:02.144Z"
   },
   {
    "duration": 1050,
    "start_time": "2025-03-13T18:24:39.047Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-13T18:24:40.098Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T18:24:40.136Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-13T18:24:40.144Z"
   },
   {
    "duration": 215,
    "start_time": "2025-03-13T18:24:40.150Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:24:40.368Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:24:40.369Z"
   },
   {
    "duration": 488,
    "start_time": "2025-03-13T18:26:33.255Z"
   },
   {
    "duration": 995,
    "start_time": "2025-03-13T18:26:44.218Z"
   },
   {
    "duration": 40,
    "start_time": "2025-03-13T18:26:45.215Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:26:45.257Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:26:45.264Z"
   },
   {
    "duration": 238,
    "start_time": "2025-03-13T18:26:45.270Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:26:45.510Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:26:45.511Z"
   },
   {
    "duration": 487,
    "start_time": "2025-03-13T18:27:11.359Z"
   },
   {
    "duration": 1055,
    "start_time": "2025-03-13T18:27:22.276Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T18:27:23.333Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:27:23.367Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-13T18:27:23.374Z"
   },
   {
    "duration": 221,
    "start_time": "2025-03-13T18:27:23.378Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:27:23.601Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-13T18:27:23.602Z"
   },
   {
    "duration": 517,
    "start_time": "2025-03-13T18:29:30.803Z"
   },
   {
    "duration": 65,
    "start_time": "2025-03-13T18:29:42.597Z"
   },
   {
    "duration": 7495,
    "start_time": "2025-03-13T18:31:33.738Z"
   },
   {
    "duration": 1011,
    "start_time": "2025-03-13T18:31:43.218Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T18:31:44.232Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:31:44.265Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-13T18:31:44.272Z"
   },
   {
    "duration": 7460,
    "start_time": "2025-03-13T18:31:44.277Z"
   },
   {
    "duration": 903,
    "start_time": "2025-03-13T18:31:51.739Z"
   },
   {
    "duration": 2155,
    "start_time": "2025-03-13T18:31:52.644Z"
   },
   {
    "duration": 472,
    "start_time": "2025-03-13T18:38:12.362Z"
   },
   {
    "duration": 1016,
    "start_time": "2025-03-13T18:38:40.405Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T18:38:41.423Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:38:41.456Z"
   },
   {
    "duration": 7531,
    "start_time": "2025-03-13T18:38:41.462Z"
   },
   {
    "duration": 1045,
    "start_time": "2025-03-13T18:39:01.535Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-13T18:39:02.582Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:39:02.614Z"
   },
   {
    "duration": 7520,
    "start_time": "2025-03-13T18:39:02.620Z"
   },
   {
    "duration": 1008,
    "start_time": "2025-03-13T18:40:02.879Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T18:40:03.889Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-13T18:40:03.922Z"
   },
   {
    "duration": 7530,
    "start_time": "2025-03-13T18:40:03.935Z"
   },
   {
    "duration": 1057,
    "start_time": "2025-03-13T18:40:28.375Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-13T18:40:29.435Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:40:29.468Z"
   },
   {
    "duration": 7590,
    "start_time": "2025-03-13T18:40:29.475Z"
   },
   {
    "duration": 1030,
    "start_time": "2025-03-13T18:47:19.037Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-13T18:47:20.069Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T18:47:20.103Z"
   },
   {
    "duration": 7694,
    "start_time": "2025-03-13T18:47:20.110Z"
   },
   {
    "duration": 1021,
    "start_time": "2025-03-13T19:06:31.601Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-13T19:06:32.624Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:06:32.658Z"
   },
   {
    "duration": 7652,
    "start_time": "2025-03-13T19:06:32.666Z"
   },
   {
    "duration": 1024,
    "start_time": "2025-03-13T19:07:55.693Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-13T19:07:56.720Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:07:56.758Z"
   },
   {
    "duration": 7706,
    "start_time": "2025-03-13T19:07:56.765Z"
   },
   {
    "duration": 1029,
    "start_time": "2025-03-13T19:09:45.493Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-13T19:09:46.524Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:09:46.561Z"
   },
   {
    "duration": 8254,
    "start_time": "2025-03-13T19:09:46.568Z"
   },
   {
    "duration": 1028,
    "start_time": "2025-03-13T19:13:06.388Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T19:13:07.419Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:13:07.452Z"
   },
   {
    "duration": 7842,
    "start_time": "2025-03-13T19:13:07.458Z"
   },
   {
    "duration": 32741,
    "start_time": "2025-03-13T19:13:15.302Z"
   },
   {
    "duration": 2355,
    "start_time": "2025-03-13T19:13:48.050Z"
   },
   {
    "duration": 1074,
    "start_time": "2025-03-13T19:15:37.355Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-13T19:15:38.431Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:15:38.465Z"
   },
   {
    "duration": 7793,
    "start_time": "2025-03-13T19:15:38.472Z"
   },
   {
    "duration": 1065,
    "start_time": "2025-03-13T19:18:06.148Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-13T19:18:07.216Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:18:07.253Z"
   },
   {
    "duration": 7684,
    "start_time": "2025-03-13T19:18:07.260Z"
   },
   {
    "duration": 32725,
    "start_time": "2025-03-13T19:18:14.946Z"
   },
   {
    "duration": 2581,
    "start_time": "2025-03-13T19:18:47.674Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-13T19:24:26.581Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:25:22.715Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:25:36.155Z"
   },
   {
    "duration": 990,
    "start_time": "2025-03-13T19:25:50.427Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T19:25:51.420Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:25:51.453Z"
   },
   {
    "duration": 7495,
    "start_time": "2025-03-13T19:25:51.459Z"
   },
   {
    "duration": 29575,
    "start_time": "2025-03-13T19:25:58.957Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-13T19:26:28.534Z"
   },
   {
    "duration": 1033,
    "start_time": "2025-03-13T19:27:49.876Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T19:27:50.911Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:27:50.944Z"
   },
   {
    "duration": 7552,
    "start_time": "2025-03-13T19:27:50.951Z"
   },
   {
    "duration": 25468,
    "start_time": "2025-03-13T19:27:58.505Z"
   },
   {
    "duration": 60,
    "start_time": "2025-03-13T19:28:23.976Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:28:55.672Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-13T19:29:35.664Z"
   },
   {
    "duration": 1035,
    "start_time": "2025-03-13T19:32:04.046Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-13T19:32:05.084Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-13T19:32:05.117Z"
   },
   {
    "duration": 7539,
    "start_time": "2025-03-13T19:32:05.133Z"
   },
   {
    "duration": 28864,
    "start_time": "2025-03-13T19:32:12.674Z"
   },
   {
    "duration": 1028,
    "start_time": "2025-03-13T19:47:06.088Z"
   },
   {
    "duration": 34,
    "start_time": "2025-03-13T19:47:07.117Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-13T19:47:07.152Z"
   },
   {
    "duration": 8130,
    "start_time": "2025-03-13T19:47:07.163Z"
   },
   {
    "duration": 31943,
    "start_time": "2025-03-13T19:47:15.296Z"
   },
   {
    "duration": 1026,
    "start_time": "2025-03-13T19:50:33.972Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-13T19:50:35.001Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-13T19:50:35.034Z"
   },
   {
    "duration": 7534,
    "start_time": "2025-03-13T19:50:35.041Z"
   },
   {
    "duration": 29588,
    "start_time": "2025-03-13T19:50:42.578Z"
   },
   {
    "duration": 1014171,
    "start_time": "2025-03-13T19:51:12.167Z"
   },
   {
    "duration": 235,
    "start_time": "2025-03-14T00:34:46.329Z"
   },
   {
    "duration": 3041,
    "start_time": "2025-03-14T00:35:04.472Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-14T00:35:07.516Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T00:35:07.555Z"
   },
   {
    "duration": 8435,
    "start_time": "2025-03-14T00:35:07.562Z"
   },
   {
    "duration": 31217,
    "start_time": "2025-03-14T00:35:16.001Z"
   },
   {
    "duration": 714,
    "start_time": "2025-03-14T00:35:47.220Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T00:35:47.935Z"
   },
   {
    "duration": 79,
    "start_time": "2025-03-14T00:46:49.564Z"
   },
   {
    "duration": 1022,
    "start_time": "2025-03-14T01:01:07.330Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-14T01:01:08.354Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:01:08.390Z"
   },
   {
    "duration": 7420,
    "start_time": "2025-03-14T01:01:08.397Z"
   },
   {
    "duration": 31196,
    "start_time": "2025-03-14T01:01:15.819Z"
   },
   {
    "duration": 1024,
    "start_time": "2025-03-14T01:02:24.847Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-14T01:02:25.874Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:02:25.908Z"
   },
   {
    "duration": 7650,
    "start_time": "2025-03-14T01:02:25.915Z"
   },
   {
    "duration": 246,
    "start_time": "2025-03-14T01:02:33.569Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:02:33.817Z"
   },
   {
    "duration": 30711,
    "start_time": "2025-03-14T01:02:46.166Z"
   },
   {
    "duration": 1338,
    "start_time": "2025-03-14T01:13:18.840Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:13:20.180Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:13:20.182Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:13:20.183Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:13:20.184Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:13:20.186Z"
   },
   {
    "duration": 1353,
    "start_time": "2025-03-14T01:14:20.892Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:14:22.246Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:14:22.247Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:14:22.249Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:14:22.250Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T01:14:22.252Z"
   },
   {
    "duration": 997,
    "start_time": "2025-03-14T01:16:39.459Z"
   },
   {
    "duration": 251,
    "start_time": "2025-03-14T01:16:40.458Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:16:40.710Z"
   },
   {
    "duration": 7632,
    "start_time": "2025-03-14T01:16:40.717Z"
   },
   {
    "duration": 29419,
    "start_time": "2025-03-14T01:16:48.351Z"
   },
   {
    "duration": 43624,
    "start_time": "2025-03-14T01:17:17.772Z"
   },
   {
    "duration": 284,
    "start_time": "2025-03-14T01:24:49.930Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-14T01:25:09.260Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-14T01:25:46.894Z"
   },
   {
    "duration": 986,
    "start_time": "2025-03-14T01:28:39.733Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-14T01:28:40.722Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-14T01:28:40.757Z"
   },
   {
    "duration": 7462,
    "start_time": "2025-03-14T01:28:40.772Z"
   },
   {
    "duration": 27369,
    "start_time": "2025-03-14T01:28:48.237Z"
   },
   {
    "duration": 829,
    "start_time": "2025-03-14T01:29:15.608Z"
   },
   {
    "duration": 1028,
    "start_time": "2025-03-14T01:30:20.210Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-14T01:30:21.240Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:30:21.278Z"
   },
   {
    "duration": 7423,
    "start_time": "2025-03-14T01:30:21.285Z"
   },
   {
    "duration": 32861,
    "start_time": "2025-03-14T01:30:28.710Z"
   },
   {
    "duration": 755,
    "start_time": "2025-03-14T01:31:01.573Z"
   },
   {
    "duration": 1022,
    "start_time": "2025-03-14T01:32:03.489Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-14T01:32:04.513Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:32:04.547Z"
   },
   {
    "duration": 7476,
    "start_time": "2025-03-14T01:32:04.554Z"
   },
   {
    "duration": 34558,
    "start_time": "2025-03-14T01:32:12.032Z"
   },
   {
    "duration": 42994,
    "start_time": "2025-03-14T01:32:46.593Z"
   },
   {
    "duration": 994,
    "start_time": "2025-03-14T01:34:49.563Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-14T01:34:50.559Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:34:50.594Z"
   },
   {
    "duration": 7449,
    "start_time": "2025-03-14T01:34:50.601Z"
   },
   {
    "duration": 27017,
    "start_time": "2025-03-14T01:34:58.053Z"
   },
   {
    "duration": 40110,
    "start_time": "2025-03-14T01:35:25.073Z"
   },
   {
    "duration": 1021,
    "start_time": "2025-03-14T01:38:30.791Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-14T01:38:31.814Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-14T01:38:31.850Z"
   },
   {
    "duration": 7438,
    "start_time": "2025-03-14T01:38:31.856Z"
   },
   {
    "duration": 31779,
    "start_time": "2025-03-14T01:38:39.296Z"
   },
   {
    "duration": 1030,
    "start_time": "2025-03-14T01:40:20.945Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-14T01:40:21.977Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:40:22.012Z"
   },
   {
    "duration": 7436,
    "start_time": "2025-03-14T01:40:22.018Z"
   },
   {
    "duration": 25614,
    "start_time": "2025-03-14T01:40:29.457Z"
   },
   {
    "duration": 1040,
    "start_time": "2025-03-14T01:43:58.882Z"
   },
   {
    "duration": 39,
    "start_time": "2025-03-14T01:43:59.925Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-14T01:43:59.965Z"
   },
   {
    "duration": 7442,
    "start_time": "2025-03-14T01:43:59.974Z"
   },
   {
    "duration": 27765,
    "start_time": "2025-03-14T01:44:07.419Z"
   },
   {
    "duration": 2813,
    "start_time": "2025-03-14T03:17:25.604Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-14T03:17:28.420Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T03:17:28.466Z"
   },
   {
    "duration": 7788,
    "start_time": "2025-03-14T03:17:28.473Z"
   },
   {
    "duration": 32857,
    "start_time": "2025-03-14T03:17:36.264Z"
   },
   {
    "duration": 1590440,
    "start_time": "2025-03-14T03:18:09.123Z"
   },
   {
    "duration": 210,
    "start_time": "2025-03-14T20:02:00.852Z"
   },
   {
    "duration": 3353,
    "start_time": "2025-03-14T20:02:07.127Z"
   },
   {
    "duration": 50,
    "start_time": "2025-03-14T20:02:10.482Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-14T20:02:10.534Z"
   },
   {
    "duration": 8638,
    "start_time": "2025-03-14T20:02:10.545Z"
   },
   {
    "duration": 362,
    "start_time": "2025-03-14T20:02:19.186Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:02:19.549Z"
   },
   {
    "duration": 1533,
    "start_time": "2025-03-14T20:03:06.845Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:03:08.381Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:03:08.382Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:03:08.389Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:03:08.390Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:03:08.391Z"
   },
   {
    "duration": 1157,
    "start_time": "2025-03-14T20:06:55.423Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-14T20:06:56.582Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T20:06:56.625Z"
   },
   {
    "duration": 8841,
    "start_time": "2025-03-14T20:06:56.633Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-14T20:07:05.477Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-14T20:07:05.486Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-14T20:08:06.246Z"
   },
   {
    "duration": 596,
    "start_time": "2025-03-14T20:08:52.404Z"
   },
   {
    "duration": 1208,
    "start_time": "2025-03-14T20:09:32.488Z"
   },
   {
    "duration": 49,
    "start_time": "2025-03-14T20:09:33.701Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T20:09:33.752Z"
   },
   {
    "duration": 8997,
    "start_time": "2025-03-14T20:09:33.759Z"
   },
   {
    "duration": 1447382,
    "start_time": "2025-03-14T20:09:42.759Z"
   },
   {
    "duration": 2080708,
    "start_time": "2025-03-14T20:33:50.143Z"
   },
   {
    "duration": 167,
    "start_time": "2025-03-14T21:50:58.413Z"
   },
   {
    "duration": 2763,
    "start_time": "2025-03-14T21:51:23.154Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-14T21:51:25.920Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T21:51:25.958Z"
   },
   {
    "duration": 8442,
    "start_time": "2025-03-14T21:51:25.965Z"
   },
   {
    "duration": 1366234,
    "start_time": "2025-03-14T21:51:34.409Z"
   },
   {
    "duration": 207691,
    "start_time": "2025-03-14T22:14:20.711Z"
   },
   {
    "duration": 2622,
    "start_time": "2025-03-15T00:28:35.007Z"
   },
   {
    "duration": 53,
    "start_time": "2025-03-15T00:28:37.632Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-15T00:28:37.687Z"
   },
   {
    "duration": 7679,
    "start_time": "2025-03-15T00:28:37.693Z"
   },
   {
    "duration": 2768,
    "start_time": "2025-03-15T01:43:26.049Z"
   },
   {
    "duration": 40,
    "start_time": "2025-03-15T01:43:28.819Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-15T01:43:28.861Z"
   },
   {
    "duration": 7328,
    "start_time": "2025-03-15T01:43:28.869Z"
   },
   {
    "duration": 1275450,
    "start_time": "2025-03-15T01:43:36.198Z"
   },
   {
    "duration": 179715,
    "start_time": "2025-03-15T02:04:51.650Z"
   },
   {
    "duration": 1746260,
    "start_time": "2025-03-15T02:07:51.366Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
